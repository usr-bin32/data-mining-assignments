{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame, cols_ord=[], cats_ord=[], cols_nom=[], cols_num=[]):\n",
    "    cols_ord_ = list(set(cols_ord) & set(df.columns))\n",
    "    cats_ord_ = [cats_ord[cols_ord.index(col)] for col in cols_ord_]\n",
    "    cols_nom_ = list(set(cols_nom) & set(df.columns))\n",
    "    cols_num_ = list(set(cols_num) & set(df.columns))\n",
    "\n",
    "    transformers = []\n",
    "    if cols_ord_:\n",
    "        transform = (OrdinalEncoder(categories=cats_ord_), cols_ord_)\n",
    "        transformers.append(transform)\n",
    "    if cols_nom_:\n",
    "        transform = (OneHotEncoder(), cols_nom_)\n",
    "        transformers.append(transform)\n",
    "    if cols_num_:\n",
    "        transform = (StandardScaler(), cols_num_)\n",
    "        transformers.append(transform)\n",
    "\n",
    "    if transformers:\n",
    "        steps = [(\"transformer\", make_column_transformer(*transformers))]\n",
    "        return Pipeline(steps).fit_transform(df)\n",
    "    else:\n",
    "        return df.to_numpy()\n",
    "\n",
    "\n",
    "def search(X, y, path=None, read_cache=True, n_jobs=-1):\n",
    "    try:\n",
    "        if path is not None and read_cache:\n",
    "            with open(path, \"rb\") as file:\n",
    "                results = pickle.load(file)\n",
    "        else:\n",
    "            raise FileNotFoundError()\n",
    "    except FileNotFoundError:\n",
    "        pipe = Pipeline([(\"estimator\", LogisticRegression())])\n",
    "        search = GridSearchCV(\n",
    "            pipe,\n",
    "            param_grid=[\n",
    "                {\"estimator\": [LogisticRegression()], \"estimator__penalty\": [\"l1\"]},\n",
    "                {\n",
    "                    \"estimator\": [DecisionTreeClassifier()],\n",
    "                    \"estimator__max_depth\": [10, 20, None],\n",
    "                },\n",
    "                {\n",
    "                    \"estimator\": [RandomForestClassifier()],\n",
    "                    \"estimator__n_estimators\": [100, 250, 1000],\n",
    "                },\n",
    "            ],\n",
    "            n_jobs=n_jobs,\n",
    "            scoring=\"f1_micro\",\n",
    "        )\n",
    "        _ = search.fit(X, y)\n",
    "        results = pd.DataFrame(search.cv_results_).sort_values(\n",
    "            by=\"mean_test_score\", ascending=False\n",
    "        )\n",
    "        if path is not None:\n",
    "            with open(path, \"wb\") as file:\n",
    "                pickle.dump(results, file)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Características\n",
    "df_sociais = pd.read_csv(\"data/trabalho5_dados_sociais_4.csv\")\n",
    "df_modulo1 = pd.read_csv(\"data/trabalho5_dados_modulo1_4.csv\")\n",
    "df_modulo2 = pd.read_csv(\"data/trabalho5_dados_ateh_modulo2_4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relações entre características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relações entre características e rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rótulos\n",
    "y = LabelEncoder().fit([\"Não\", \"Sim\"]).transform(df_modulo2[\"aprovado\"])\n",
    "df_sociais = df_sociais.drop([\"id\", \"aprovado\"], axis=1)\n",
    "df_modulo1 = df_modulo1.drop([\"id\", \"aprovado\"], axis=1)\n",
    "df_modulo2 = df_modulo2.drop([\"id\", \"aprovado\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordens das categorias\n",
    "sn_cat = [\"Não\", \"Sim\"]\n",
    "sexo_cat = [\"Feminino\", \"Masculino\"]\n",
    "escolaridade_cat = [\n",
    "    \"Ensino Médio Completo\",\n",
    "    \"Ensino Superior Incompleto\",\n",
    "    \"Ensino Superior Completo\",\n",
    "    \"Pós-graduação\",\n",
    "]\n",
    "materialdidatico_cat = [\"Adequado\", \"Muito adequado\"]\n",
    "prazoatividades_cat = [\n",
    "    \"Pouquíssimo flexível\",\n",
    "    \"Pouco flexível\",\n",
    "    \"Flexível\",\n",
    "    \"Muito flexível\",\n",
    "]\n",
    "interacaopares_cat = [\"Importante\", \"Muito importante\"]\n",
    "organizacaocurso_cat = [\"Organizado\", \"Muito organizado\"]\n",
    "import_ajud_tutor_cat = [\"Às vezes\", \"Sempre\"]\n",
    "autoavaliacao_cat = [\n",
    "    \"Não, não considero\",\n",
    "    \"Sim, considero, porém, poderia estar me esforçando mais\",\n",
    "    \"Sim, considero\",\n",
    "]\n",
    "pp_cat = [\n",
    "    \"Discordo totalmente\",\n",
    "    \"Discordo\",\n",
    "    \"Nem discordo, nem concordo\",\n",
    "    \"Concordo\",\n",
    "    \"Concordo totalmente\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis ordinais\n",
    "cols_ord = [\n",
    "    \"escolaridade\",\n",
    "    \"materialdidatico\",\n",
    "    \"prazoatividades\",\n",
    "    \"interacaopares\",\n",
    "    \"import.ajud.tutor\",\n",
    "    \"autoavaliacao.x\",\n",
    "] + [f\"pp{n + 1:03}\" for n in range(37)]\n",
    "cats_ord = [\n",
    "    escolaridade_cat,\n",
    "    materialdidatico_cat,\n",
    "    prazoatividades_cat,\n",
    "    interacaopares_cat,\n",
    "    import_ajud_tutor_cat,\n",
    "    autoavaliacao_cat,\n",
    "] + [pp_cat] * 37\n",
    "\n",
    "# Variáveis nominais\n",
    "cols_nom = list(set(df_sociais.select_dtypes(object).columns) - set(cols_ord))\n",
    "\n",
    "# Variáveis numéricas\n",
    "cols_num = [\"idade\", \"tempodeservico\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.        ,  1.        ,  3.        , ...,  0.        ,\n",
       "        -0.11217859,  0.65818824],\n",
       "       [ 3.        ,  1.        ,  3.        , ...,  1.        ,\n",
       "         0.41079851,  1.40819926],\n",
       "       [ 3.        ,  1.        ,  3.        , ...,  0.        ,\n",
       "         0.41079851,  0.33675495],\n",
       "       ...,\n",
       "       [ 3.        ,  1.        ,  3.        , ...,  0.        ,\n",
       "         0.01856569, -1.27041153],\n",
       "       [ 3.        ,  1.        ,  3.        , ...,  0.        ,\n",
       "         0.28005423,  0.01532165],\n",
       "       [ 3.        ,  1.        ,  3.        , ...,  0.        ,\n",
       "         0.14930996,  0.87247711]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sociais = preprocess(df_sociais, cols_ord, cats_ord, cols_nom, cols_num)\n",
    "X_modulo1 = preprocess(df_modulo1, cols_ord, cats_ord, cols_nom, cols_num)\n",
    "X_modulo2 = preprocess(df_modulo2, cols_ord, cats_ord, cols_nom, cols_num)\n",
    "\n",
    "X_sociais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação: Dados socioeconômicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Work\\miniconda3\\envs\\data-science\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 35.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Work\\miniconda3\\envs\\data-science\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Work\\miniconda3\\envs\\data-science\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Work\\miniconda3\\envs\\data-science\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Work\\miniconda3\\envs\\data-science\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Work\\miniconda3\\envs\\data-science\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [  nan 0.51  0.496 0.479 0.478 0.48  0.48 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1632/3637045312.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(X, y, path, cache, n_jobs)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1632/657882293.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_sociais\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1632/3637045312.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(X, y, path, cache, n_jobs)\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mean_test_score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         )\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not DataFrame"
     ]
    }
   ],
   "source": [
    "search(X_sociais, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação: Dados socioeconômicos + primeiro módulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação: Todos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c790b6eca2cff74a0fee1fdb02e8ff00847e34f37ce710d1cac69b6dcbe2045e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('data-science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
